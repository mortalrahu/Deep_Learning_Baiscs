{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f12048c-0087-40d6-96ef-318b8717c9b9",
   "metadata": {},
   "source": [
    "**Sentiment Analysis:**\n",
    "Sentiment analysis, also known as opinion mining, is the process of determining the sentiment or emotional tone conveyed in a piece of text. It involves analyzing and classifying text data to identify whether the expressed sentiment is positive, negative, or neutral. The goal is to understand the subjective information within the text and extract insights about the author's opinion or attitude.\n",
    "\n",
    "**Experiment Design for Sentiment Analysis with Keras:**\n",
    "\n",
    "**Objective:** Build a basic sentiment analysis model using Keras to classify movie reviews as positive or negative.\n",
    "\n",
    "**Dataset:** Use the IMDB Movie Reviews dataset, which is available in the Keras datasets module. This dataset contains 50,000 movie reviews labeled as positive (1) or negative (0).\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1bbfe4a3-e0ea-4e89-9a84-bcb7840d8b40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n"
     ]
    }
   ],
   "source": [
    "# Load and Process the dataset\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense\n",
    "\n",
    "# Load IMDB dataset\n",
    "from keras.datasets import imdb\n",
    "\n",
    "# Load only the top 10,000 most frequently occurring words\n",
    "max_words = 10000\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=max_words)\n",
    "\n",
    "print(X_train[0])\n",
    "\n",
    "# Preprocess the data (sequence padding)\n",
    "from keras.preprocessing import sequence\n",
    "maxlen = 100  # Limit the review length to 100 words\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=maxlen)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=maxlen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32720053-703a-44d6-b704-869b5a816e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=max_words, output_dim=32))#, input_length=maxlen))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da5a3ae7-c169-4871-8990-11a66a04951e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 40ms/step - accuracy: 0.9346 - loss: 0.1818 - val_accuracy: 0.8421 - val_loss: 0.3813\n",
      "Epoch 2/50\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 41ms/step - accuracy: 0.9548 - loss: 0.1343 - val_accuracy: 0.8229 - val_loss: 0.4095\n",
      "Epoch 3/50\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 41ms/step - accuracy: 0.9524 - loss: 0.1309 - val_accuracy: 0.8344 - val_loss: 0.4843\n",
      "Epoch 4/50\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 41ms/step - accuracy: 0.9697 - loss: 0.0912 - val_accuracy: 0.8285 - val_loss: 0.5500\n",
      "Epoch 5/50\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 42ms/step - accuracy: 0.9787 - loss: 0.0645 - val_accuracy: 0.8243 - val_loss: 0.6760\n",
      "Epoch 6/50\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 42ms/step - accuracy: 0.9839 - loss: 0.0480 - val_accuracy: 0.8283 - val_loss: 0.6762\n",
      "Epoch 7/50\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 41ms/step - accuracy: 0.9835 - loss: 0.0465 - val_accuracy: 0.8259 - val_loss: 0.8137\n",
      "Epoch 8/50\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 43ms/step - accuracy: 0.9851 - loss: 0.0423 - val_accuracy: 0.8208 - val_loss: 0.7862\n",
      "Epoch 9/50\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 43ms/step - accuracy: 0.9894 - loss: 0.0335 - val_accuracy: 0.8219 - val_loss: 0.8413\n",
      "Epoch 10/50\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 43ms/step - accuracy: 0.9903 - loss: 0.0321 - val_accuracy: 0.8091 - val_loss: 0.8199\n",
      "Epoch 11/50\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 43ms/step - accuracy: 0.9953 - loss: 0.0184 - val_accuracy: 0.8203 - val_loss: 0.9535\n",
      "Epoch 12/50\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 43ms/step - accuracy: 0.9952 - loss: 0.0167 - val_accuracy: 0.8165 - val_loss: 0.9852\n",
      "Epoch 13/50\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 42ms/step - accuracy: 0.9897 - loss: 0.0340 - val_accuracy: 0.8203 - val_loss: 1.0602\n",
      "Epoch 14/50\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 42ms/step - accuracy: 0.9960 - loss: 0.0154 - val_accuracy: 0.8152 - val_loss: 0.8798\n",
      "Epoch 15/50\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 42ms/step - accuracy: 0.9960 - loss: 0.0146 - val_accuracy: 0.8168 - val_loss: 1.0657\n",
      "Epoch 16/50\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 43ms/step - accuracy: 0.9968 - loss: 0.0101 - val_accuracy: 0.8195 - val_loss: 1.1782\n",
      "Epoch 17/50\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 42ms/step - accuracy: 0.9984 - loss: 0.0054 - val_accuracy: 0.8096 - val_loss: 1.2510\n",
      "Epoch 18/50\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 42ms/step - accuracy: 0.9968 - loss: 0.0103 - val_accuracy: 0.8189 - val_loss: 1.2519\n",
      "Epoch 19/50\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 42ms/step - accuracy: 0.9958 - loss: 0.0142 - val_accuracy: 0.8189 - val_loss: 0.9909\n",
      "Epoch 20/50\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 42ms/step - accuracy: 0.9952 - loss: 0.0166 - val_accuracy: 0.8211 - val_loss: 1.1919\n",
      "Epoch 21/50\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 42ms/step - accuracy: 0.9991 - loss: 0.0042 - val_accuracy: 0.8216 - val_loss: 1.1889\n",
      "Epoch 22/50\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 42ms/step - accuracy: 0.9949 - loss: 0.0170 - val_accuracy: 0.8101 - val_loss: 1.0420\n",
      "Epoch 23/50\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 42ms/step - accuracy: 0.9962 - loss: 0.0124 - val_accuracy: 0.8173 - val_loss: 1.2383\n",
      "Epoch 24/50\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 43ms/step - accuracy: 0.9965 - loss: 0.0118 - val_accuracy: 0.8160 - val_loss: 1.1013\n",
      "Epoch 25/50\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 43ms/step - accuracy: 0.9992 - loss: 0.0048 - val_accuracy: 0.8213 - val_loss: 1.1901\n",
      "Epoch 26/50\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 43ms/step - accuracy: 0.9995 - loss: 0.0032 - val_accuracy: 0.8147 - val_loss: 1.3203\n",
      "Epoch 27/50\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 43ms/step - accuracy: 0.9980 - loss: 0.0075 - val_accuracy: 0.8128 - val_loss: 1.2462\n",
      "Epoch 28/50\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 43ms/step - accuracy: 0.9994 - loss: 0.0022 - val_accuracy: 0.8152 - val_loss: 1.4145\n",
      "Epoch 29/50\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 43ms/step - accuracy: 0.9969 - loss: 0.0100 - val_accuracy: 0.8101 - val_loss: 1.0270\n",
      "Epoch 30/50\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 42ms/step - accuracy: 0.9957 - loss: 0.0161 - val_accuracy: 0.8184 - val_loss: 1.0614\n",
      "Epoch 31/50\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 43ms/step - accuracy: 0.9978 - loss: 0.0085 - val_accuracy: 0.8219 - val_loss: 1.0954\n",
      "Epoch 32/50\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 44ms/step - accuracy: 0.9992 - loss: 0.0036 - val_accuracy: 0.8117 - val_loss: 1.0882\n",
      "Epoch 33/50\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 44ms/step - accuracy: 0.9981 - loss: 0.0064 - val_accuracy: 0.8189 - val_loss: 1.1737\n",
      "Epoch 34/50\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 9.0627e-04 - val_accuracy: 0.8213 - val_loss: 1.3489\n",
      "Epoch 35/50\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 2.1562e-04 - val_accuracy: 0.8208 - val_loss: 1.4250\n",
      "Epoch 36/50\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 1.0734e-04 - val_accuracy: 0.8211 - val_loss: 1.4877\n",
      "Epoch 37/50\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 7.3707e-05 - val_accuracy: 0.8192 - val_loss: 1.5354\n",
      "Epoch 38/50\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 5.2200e-05 - val_accuracy: 0.8189 - val_loss: 1.5738\n",
      "Epoch 39/50\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 3.8462e-05 - val_accuracy: 0.8189 - val_loss: 1.6135\n",
      "Epoch 40/50\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 3.0317e-05 - val_accuracy: 0.8192 - val_loss: 1.6487\n",
      "Epoch 41/50\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 2.3793e-05 - val_accuracy: 0.8195 - val_loss: 1.6891\n",
      "Epoch 42/50\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.9382e-05 - val_accuracy: 0.8203 - val_loss: 1.7256\n",
      "Epoch 43/50\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.4590e-05 - val_accuracy: 0.8200 - val_loss: 1.7578\n",
      "Epoch 44/50\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 1.2559e-05 - val_accuracy: 0.8195 - val_loss: 1.7882\n",
      "Epoch 45/50\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 1.0016e-05 - val_accuracy: 0.8200 - val_loss: 1.8257\n",
      "Epoch 46/50\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 7.8928e-06 - val_accuracy: 0.8200 - val_loss: 1.8581\n",
      "Epoch 47/50\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 6.4136e-06 - val_accuracy: 0.8203 - val_loss: 1.8951\n",
      "Epoch 48/50\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 4.9161e-06 - val_accuracy: 0.8189 - val_loss: 1.9178\n",
      "Epoch 49/50\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 4.1783e-06 - val_accuracy: 0.8197 - val_loss: 1.9568\n",
      "Epoch 50/50\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 3.0947e-06 - val_accuracy: 0.8203 - val_loss: 1.9828\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1a97ee6fa50>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=64, validation_split=0.15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b0ab1150-8760-4f19-abe1-dddbb0a2c4c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.8147 - loss: 2.0118\n",
      "Test Accuracy: 81.38%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c660b59f-894a-42b2-93c7-bfa690545724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[13, 447, 14, 20], [4, 114, 16, 1499], [54485, 14, 20]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Review: I loved this movie!\n",
      "Sentiment: Positive\n",
      "\n",
      "Review: The plot was confusing.\n",
      "Sentiment: Positive\n",
      "\n",
      "Review: Fuck this movie\n",
      "Sentiment: Positive\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert text to lowercase and remove punctuation\n",
    "import string\n",
    "translator = str.maketrans('', '', string.punctuation)\n",
    "\n",
    "new_reviews = [\"I loved this movie!\", \"The plot was confusing.\", \"Fuck this movie\"]\n",
    "\n",
    "# Preprocess the input text\n",
    "new_sequences = []\n",
    "for review in new_reviews:\n",
    "    review = review.lower().translate(translator).split()\n",
    "    sequence = [imdb.get_word_index().get(word, 2) + 3 for word in review]  # Offset by 3\n",
    "    new_sequences.append(sequence)\n",
    "\n",
    "print(new_sequences)\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "# Pad sequences\n",
    "new_sequences = sequence.pad_sequences(new_sequences, maxlen=maxlen)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(new_sequences)\n",
    "\n",
    "for review, prediction in zip(new_reviews, predictions):\n",
    "    sentiment = \"Positive\" if prediction >= 0.5 else \"Negative\"\n",
    "    print(f\"Review: {review}\\nSentiment: {sentiment}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06f040b-7025-44dc-9edc-653330a18f5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
